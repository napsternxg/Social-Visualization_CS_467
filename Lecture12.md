## Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design
### 1) a two sentence summary (do *not* simply summarize the work in your write-up)
The paper aims to address the viability of using crowdsourcing platforms to evaluate graphical visualizations. They focus on the use of Amazon's mechanical turk for their study. They find that the platform does give a diversified pool of users which can help is better evaluation of visualizations.

### 2) what you feel are the positives of the work, i.e. what is exceptional
I think the result about the kind of tasks giving best results using crowdsourcing is the best thing about the paper. They show that classification tasks gives the best quality responses. Another interesting result of the paper is the extension of the classification exercise for visualizations leading to figuring out optimal chart heights. The experiments also highlights some of the suggested techniques we use in everyday visualizations.  

### 3) what you think could use improvement
I think the paper could have been improved if the authors could have used different kinds of visualizations to be judged by the Turkers. In all their experiments the visualizations changed slightly in size and alpha. It would be interesting to know if the Turkers can give useful insights into the differences of 2 different visualizations like bar chart versus pie charts. 

### 4) how you might continue the work or what you might pursue next
I would want to continue this work by developing a study for analyzing how turkers perform on different kinds of visualizations. Another interesting extension would be how different the results will be if we gave $0 cost compared to the $0.02 or $0.04 as mentioned in the paper.

## What Makes a Visualization Memorable?
### 1) a two sentence summary (do *not* simply summarize the work in your write-up)
The paper describes the largest study till its time with 2070 visualizations panels from various sources. It talks about the measure of memorability of these visualizations using the data from Mechanical Turks. The paper concludes that non trivial visualizations are more memorable. 

### 2) what you feel are the positives of the work, i.e. what is exceptional
I think the extensiveness of this work really makes it significant. Their result on the memorability of a visualization as a metric to measure the effectiveness of a visualization is great. Another important input of this study is their mechanism to identify the workers who were not paying attention by repeating the images at the gap of 7-8 images. 

### 3) what you think could use improvement
The final study on just 410 target visualizations is probably not a very effective way of judging the results of the experiment. Also, there is no information about the background of the turkers and how that might be impacting their memorability of the visualizations. 

### 4) how you might continue the work or what you might pursue next
I would like to extend this study by also taking into account the diversity of the turkers and choosing turkers from various demographics and check if the results are consistent across various demographics. Females may like colors more than males. Kids may like bar charts more than heat maps.
